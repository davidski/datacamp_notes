---
title: "Sentiment Analysis"
output: html_notebook
---

```{r setup}
library(tidytext)
library(tidyverse)
data_dir <- "data/tidy_sentiment"
```

```{r}
get_sentiments("bing")
get_sentiments("nrc") %>% count(sentiment)
```

# Twitter Data

```{r}
load(here::here(data_dir, "geocoded_tweets.rda"))
geocoded_tweets %>% #filter(state == "washington") %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(state, sentiment, wt = freq) %>% 
  group_by(state) %>% mutate(n = n / sum(n))
```

```{r}
tweets_bing <- geocoded_tweets %>% inner_join(get_sentiments("bing"))

tweets_bing %>% 
  # Group by two columns: state and sentiment
  group_by(state, sentiment) %>%
  # Use summarize to calculate the mean frequency for these groups
  summarize(freq = mean(freq)) %>%
  spread(sentiment, freq) %>%
  ungroup() %>%
  # Calculate the ratio of positive to negative words
  mutate(ratio = positive / negative,
         state = reorder(state, ratio)) %>%
  # Use aes() to put state on the x-axis and ratio on the y-axis
  ggplot(aes(state, ratio)) +
  # Make a plot with points using geom_point()
  geom_point() +
  labs(y = "Ratio Pos:Neg") +
  coord_flip() +
  hrbrthemes::theme_ipsum()
```

# Shakespeare Data

```{r}
load(here::here(data_dir, "shakespeare.rda"))
shakespeare %>% count(type, title)
```

```{r}
shakespeare %>% unnest_tokens(word, text)
```

```{r}
shakespeare %>% unnest_tokens(word, text) %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(title, word, sentiment, sort = TRUE)
```

# TV Captions

```{r}
load(here::here(data_dir, "climate_text.rda"))
tidy_tv <- climate_text %>% 
  unnest_tokens(word, text)
tidy_tv
```

```{r}
tidy_tv %>% 
    anti_join(stop_words) %>%
    # Count by word with sort = TRUE
    count(word, sort = TRUE)
    
tidy_tv %>%
    # Count by station
    count(station) %>%
    # Rename the new column station_total
    rename(station_total = n)
```


```{r}
tv_sentiment <- tidy_tv %>% 
    # Group by station
    group_by(station) %>% 
    # Define a new column station_total
    mutate(station_total = n()) %>%
    ungroup() %>%
    # Implement sentiment analysis with the NRC lexicon
    inner_join(get_sentiments("nrc"))
tv_sentiment
```

The group, count, ungroup paradigm feels awkward to me. We can just use `add_count` 
and `rename` instead!

```{r}
tv_sentiment <- tidy_tv %>% 
    add_count(station) %>% 
    rename(station_total = n) %>%
    # Implement sentiment analysis with the NRC lexicon
    inner_join(get_sentiments("nrc"))
tv_sentiment
```

```{r}
tv_sentiment %>% count(station, sentiment, station_total)
```

```{r}
# Which stations use the most negative words?
tv_sentiment %>% 
    count(station, sentiment, station_total) %>%
    # Define a new column percent
    mutate(percent = n / station_total) %>%
    # Filter only for negative words
    filter(sentiment == "negative") %>%
    # Arrange by percent
    arrange(percent)
    
# Now do the same but for positive words
tv_sentiment %>% 
    count(station, sentiment, station_total) %>%
    mutate(percent = n / station_total) %>%
    filter(sentiment == "positive") %>%
    # Arrange by percent
    arrange(percent)
```

```{r}
tv_sentiment %>%
    # Count by word and sentiment
    count(word, sentiment) %>%
    # Group by sentiment
    group_by(sentiment) %>%
    # Take the top 10 words for each sentiment
    top_n(10, wt = n) %>%
    ungroup() %>%
    mutate(word = reorder(word, n)) %>%
    # Set up the plot with aes()
    ggplot(aes(word, n, fill = sentiment)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ sentiment, scales = "free") +
    coord_flip()
```

Let's remove some words that shouldn't be used (proper names, not context-relevavnt, etc.).

```{r}
words_to_remove <- tibble(word = c("gore", "trump", "change"))
tv_sentiment %>%
  anti_join(words_to_remove) %>% 
    # Count by word and sentiment
    count(word, sentiment) %>%
    # Group by sentiment
    group_by(sentiment) %>%
    # Take the top 10 words for each sentiment
    top_n(10, wt = n) %>%
    ungroup() %>%
    mutate(word = reorder(word, n)) %>%
    # Set up the plot with aes()
    ggplot(aes(word, n, fill = sentiment)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~ sentiment, scales = "free") +
    coord_flip()
```

```{r}
tv_sentiment %>%
  anti_join(words_to_remove) %>% 
    # Filter for only negative words
    filter(sentiment == "negative") %>%
    # Count by word and station
    count(word, station) %>%
    # Group by station
    group_by(station) %>%
    # Take the top 10 words for each station
    top_n(10, n) %>%
    ungroup() %>%
    mutate(word = reorder(paste(word, station, sep = "__"), n)) %>%
    # Set up the plot with aes()
    ggplot(aes(word, n, fill = station)) +
    geom_col(show.legend = FALSE) +
    scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
    facet_wrap(~ station, nrow = 2, scales = "free") +
    coord_flip()
```

An alternate construction...

```{r}
tv_sentiment %>%
  anti_join(words_to_remove) %>%
  # Filter for only negative words
  filter(sentiment == "negative") %>%
  # Count by word and station
  count(word, station) %>%
  # Group by station
  group_by(station) %>%
  # Take the top 10 words for each station
  top_n(10, n) %>%
  ungroup() %>%
  mutate(word = reorder(glue::glue("{word}__{station}"), n)) %>%
  # Set up the plot with aes()
  ggplot(aes(word, n, fill = station)) +
  geom_col(show.legend = FALSE) +
  scale_x_discrete(labels = function(x) gsub("__.+$", "", x)) +
  facet_wrap( ~ station, nrow = 2, scales = "free") +
  coord_flip() +
  hrbrthemes::theme_ipsum()
```


```{r}
# Load the lubridate package
library(lubridate)

sentiment_by_time <- tidy_tv %>%
    # Define a new column using floor_date()
    mutate(date = floor_date(show_date, unit = "6 months")) %>%
    # Group by date
    group_by(date) %>%
    mutate(total_words = n()) %>%
    ungroup() %>%
    # Implement sentiment analysis using the NRC lexicon
    inner_join(get_sentiments("nrc"))

sentiment_by_time %>%
    # Filter for positive and negative words
    filter(sentiment %in% c("positive", "negative")) %>%
    # Count by date, sentiment, and total_words
    count(date, sentiment, total_words) %>%
    ungroup() %>%
    mutate(percent = n / total_words) %>%
    # Set up the plot with aes()
    ggplot(aes(date, percent, color = sentiment)) +
    geom_line(size = 1.5) +
    geom_smooth(method = "lm", se = FALSE, lty = 2) +
    expand_limits(y = 0)
```

```{r}
tidy_tv %>%
    # Define a new column that rounds each date to the nearest 1 month
    mutate(date = floor_date(show_date, unit = "1 month")) %>%
    filter(word %in% c("threat", "hoax", "denier",
                       "real", "warming", "hurricane")) %>%
    # Count by date and word
    count(date, word) %>%
    ungroup() %>%
    # Set up your plot with aes()
    ggplot(aes(date, n, color = word)) +
    # Make facets by word
    facet_wrap(~ word, scales = "free_y") +
    geom_line(size = 1.5, show.legend = FALSE) +
    expand_limits(y = 0)
```

# Pop Songs

```{r}
load(here::here(data_dir, "song_lyrics.Rda"))
tidy_lyrics <- unnest_tokens(song_lyrics, word, lyrics)
```

```{r}
totals <- tidy_lyrics %>%
  # Count by song to find the word totals for each song
  count(song) %>%
  # Rename the new column
  rename(total_words = n)

# Print totals    
totals

lyric_counts <- tidy_lyrics %>%
  # Combine totals with tidy_lyrics using the "song" column
  left_join(totals, by = "song")
```

```{r}
lyric_sentiment <- lyric_counts %>%
    # Implement sentiment analysis with the "nrc" lexicon
    inner_join(get_sentiments("nrc"))

lyric_sentiment %>%
    # Find how many sentiment words each song has
    count(song, sentiment, sort = TRUE)
```

```{r}
# What songs have the highest proportion of negative words?
lyric_sentiment %>%
    # Count using three arguments
    count(song, word, sentiment) %>%
    ungroup() %>%
    # Make a new percent column with mutate 
    mutate(percent = n / sum(n)) %>%
    # Filter for only negative words
    filter(sentiment == "negative") %>%
    # Arrange by descending percent
    arrange(desc(percent))

# What songs have the highest proportion of positive words?
lyric_sentiment %>%
    # Count using three arguments
    count(song, word, sentiment) %>%
    ungroup() %>%
    # Make a new percent column with mutate 
    mutate(percent = n / sum(n)) %>%
    # Filter for only positive words
    filter(sentiment == "positive") %>%
    # Arrange by descending percent
    arrange(desc(percent))
   
```

```{r}
# What songs have the highest proportion of negative words?
lyric_sentiment %>%
    # Count using three arguments
    count(song, sentiment, total_words) %>%
    ungroup() %>%
    # Make a new percent column with mutate 
    mutate(percent = n / total_words) %>%
    # Filter for only negative words
    filter(sentiment == "negative") %>%
    # Arrange by descending percent
    arrange(desc(percent))

# What songs have the highest proportion of positive words?
lyric_sentiment %>%
    # Count using three arguments
    count(song, sentiment, total_words) %>%
    ungroup() %>%
    # Make a new percent column with mutate 
    mutate(percent = n / total_words) %>%
    # Filter for only positive words
    filter(sentiment == "positive") %>%
    # Arrange by descending percent
    arrange(desc(percent))
   
```


```{r}
lyric_sentiment %>%
    filter(sentiment == "positive") %>%
    # Count by song, Billboard rank, and the total number of words
    count(song, rank, total_words) %>%
    ungroup() %>%
    # Use the correct dplyr verb to make two new columns
    mutate(percent = n / total_words,
           rank = 10 * floor(rank / 10)) %>%
    ggplot(aes(as.factor(rank), percent)) +
    # Make a boxplot
    geom_boxplot() + 
  hrbrthemes::theme_ipsum()
```

```{r}
lyric_sentiment %>%
    # Filter for only negative words
    filter(sentiment == "negative") %>%
    # Count by song, Billboard rank, and the total number of words
    count(song, rank, total_words) %>%
    ungroup() %>%
    # Mutate to make a percent column
    mutate(percent = n / total_words,
           rank = 10 * floor(rank / 10)) %>%
    # Use ggplot to set up a plot with rank and percent
    ggplot(aes(as.factor(rank), percent)) +
    # Make a boxplot
    geom_boxplot()
```
```{r}
# How is negative sentiment changing over time?
lyric_sentiment %>%
    # Filter for only negative words
    filter(sentiment == "negative") %>%
    # Count by song, year, and the total number of words
    count(song, year, total_words) %>%
    ungroup() %>%
    mutate(percent = n / total_words,
           year = 10 * floor(year / 10)) %>%
    # Use ggplot to set up a plot with year and percent
    ggplot(aes(as.factor(year), percent)) +
    geom_boxplot()
    
# How is positive sentiment changing over time?
lyric_sentiment %>%
    # Filter for only negative words
    filter(sentiment == "positive") %>%
    # Count by song, year, and the total number of words
    count(song, year, total_words) %>%
    ungroup() %>%
    mutate(percent = n / total_words,
           year = 10 * floor(year / 10)) %>%
    # Use ggplot to set up a plot with year and percent
    ggplot(aes(as.factor(year), percent)) +
    geom_boxplot()
```
```{r}
negative_by_year <- lyric_sentiment %>%
    # Filter for negative words
    filter(sentiment == "negative") %>%
    count(song, year, total_words) %>%
    ungroup() %>%
    # Define a new column: percent
    mutate(percent = n / total_words)

# Specify the model with percent as the response and year as the predictor
model_negative <- lm(percent ~ year, data = negative_by_year)

# Use summary to see the results of the model fitting
summary(model_negative)
```

```{r}
positive_by_year <- lyric_sentiment %>%
    # Filter for positive words
    filter(sentiment == "positive") %>%
    count(song, year, total_words) %>%
    ungroup() %>%
    # Define a new column: percent
    mutate(percent = n / total_words)

# Specify the model with percent as the response and year as the predictor
model_positive <- lm(percent ~ year, data = positive_by_year)

# Use summary to see the results of the model fitting
summary(model_positive)
```

Or we can use `broom`

```{r}
broom::tidy(model_positive)
broom::tidy(model_negative)
```

